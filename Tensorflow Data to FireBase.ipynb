{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The purpose of this file is to run our machine learning model and upload the data to Google FireBase. This file should be set to run daily, so new predictions can be uploaded to the Google FireBase. These predicted prices (plus the model RMSE) will be pulled from the database to be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1658/1658 [==============================] - 57s 34ms/step - loss: 4.3057e-04\n",
      "Root Mean Squared Value: \n",
      "10.087747498132366\n",
      "Predicted Price is: 375.42892\n",
      "AAPL complete!\n",
      "Epoch 1/1\n",
      "1658/1658 [==============================] - 59s 36ms/step - loss: 8.5752e-04\n",
      "Root Mean Squared Value: \n",
      "16.63076897893863\n",
      "Predicted Price is: 522.7446\n",
      "NFLX complete!\n",
      "Epoch 1/1\n",
      "1658/1658 [==============================] - 58s 35ms/step - loss: 4.7737e-04\n",
      "Root Mean Squared Value: \n",
      "90.69196332511449\n",
      "Predicted Price is: 3102.5134\n",
      "AMZN complete!\n",
      "Epoch 1/1\n",
      "1658/1658 [==============================] - 57s 34ms/step - loss: 1.9652e-04\n",
      "Root Mean Squared Value: \n",
      "58.22239556087326\n",
      "Predicted Price is: 1341.7794\n",
      "TSLA complete!\n",
      "Epoch 1/1\n",
      "1582/1582 [==============================] - 57s 36ms/step - loss: 0.0013\n",
      "Root Mean Squared Value: \n",
      "7.785316037293873\n",
      "Predicted Price is: 232.3465\n",
      "FB complete!\n",
      "Epoch 1/1\n",
      "1658/1658 [==============================] - 54s 32ms/step - loss: 9.6356e-04\n",
      "Root Mean Squared Value: \n",
      "47.518182735187374\n",
      "Predicted Price is: 1454.9613\n",
      "GOOG complete!\n",
      "Epoch 1/1\n",
      "1658/1658 [==============================] - 60s 36ms/step - loss: 3.5252e-04\n",
      "Root Mean Squared Value: \n",
      "11.382857470017113\n",
      "Predicted Price is: 222.51097\n",
      "MSFT complete!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from datetime import datetime, timedelta\n",
    "from firebase import firebase\n",
    "\n",
    "#Getting our data\n",
    "for stock in ['AAPL', 'NFLX', 'AMZN', 'TSLA', 'FB', 'GOOG', 'MSFT']:\n",
    "    today = datetime.now()\n",
    "    today = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df = web.DataReader(stock, data_source = 'yahoo', start = '2012-01-01', end = today)\n",
    "\n",
    "    #Creating a new dataframe with only the close column\n",
    "    data = df[['Close']]\n",
    "\n",
    "    #Converting dataframe to numpy array\n",
    "    dataset = data.values\n",
    "\n",
    "    #Get the number of rows to train the model on (we want to train on 80% of the data)\n",
    "    training_data_len = math.ceil(len(dataset) * 0.8)\n",
    "\n",
    "    #Normalizing the data - we always do this whenever we input data into machine learning models (they perform better)\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "    #Create the scaled training dataset\n",
    "    train_data = scaled_data[0: training_data_len, :]\n",
    "\n",
    "    #Split the data into x_train (independent training variables) and y_train (dependent training variables - target variable) data sets\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    #Here, we're basically taking every 60 \"timepoints\" of data, then appending the next value after that to y_train.\n",
    "    #The purpose is to use 60 data points to predict the 61st, over and over again, to train our model.\n",
    "    #0 - 59 --> we append the first y_train value (60), then 1 --> 60, we append the next y_train value (61)\n",
    "    for i in range(60, len(train_data)):\n",
    "        x_train.append(train_data[i - 60: i, 0])\n",
    "        y_train.append(train_data[i, 0])\n",
    "\n",
    "    #Convert the x_train and y_train to numpy arrays (proper format to use in the model)\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "    #Reshape the data because the model expects a 3d input: number of samples, numebr of timepoints, and number of features\n",
    "    #Right now, our data is still 2-D\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "    #Build the LSTEM Model - the model is constructed in \"layers\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
    "    model.add(LSTM(50, return_sequences = False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "    #Train the model (fit is another word for train)\n",
    "    model.fit(x_train, y_train, batch_size = 1, epochs = 1)\n",
    "\n",
    "    #Creating the normalized testing dataset\n",
    "    test_data = scaled_data[training_data_len - 60: , :]\n",
    "\n",
    "    #Creating x_test (Values we want the model to use to predict y_test) and y_test (values we want our model to predict)\n",
    "    x_test = []\n",
    "    y_test = dataset[training_data_len: , :]\n",
    "\n",
    "    for i in range(60, len(test_data)):\n",
    "        x_test.append(test_data[i - 60: i, 0])\n",
    "\n",
    "    #Converting the data to a numpy array\n",
    "    x_test = np.array(x_test)\n",
    "\n",
    "    #Reshape the data to make it 3-D (because that's what the model is expecting)\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "    #Get the models predicted price values, and un-normalizing them\n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = scaler.inverse_transform(predictions) \n",
    "\n",
    "    #Evaluating our models performance - by getting the Root Mean Square Error (RMSE)\n",
    "    #Lower values of RMSE means it's a better fit\n",
    "    #A value of 0 mean that the predictions are perfect\n",
    "    rmse = np.sqrt(np.mean(((predictions - y_test)**2)))\n",
    "    print('Root Mean Squared Value: ')\n",
    "    print(rmse)\n",
    "\n",
    "    #Let's try to make a prediction\n",
    "    #Getting the data\n",
    "    apple_quote2 = web.DataReader(stock, data_source = 'yahoo', start = '2012-01-01', end = today)\n",
    "\n",
    "    #Create a new dataframe\n",
    "    new_df = apple_quote2[['Close']]\n",
    "\n",
    "    #Get the last 60 days of closing price values and convert the dataframe to an array\n",
    "    last_60_days = new_df[-60:].values\n",
    "\n",
    "    #Normalizing the data\n",
    "    last_60_days_normalized = scaler.transform(last_60_days)\n",
    "\n",
    "    #Create an empty list and appending the last 60 days worth of data\n",
    "    X_test = []\n",
    "    X_test.append(last_60_days_normalized)\n",
    "\n",
    "    #Convert the X_test dataset to a numpy array\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    #Reshaping the data\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    #Getting the predicted, normalized price\n",
    "    predicted_price = model.predict(X_test)\n",
    "\n",
    "    #Undo the normalization to get the actual price\n",
    "    predicted_price = scaler.inverse_transform(predicted_price)\n",
    "    print(\"Predicted Price is: \" + str(predicted_price[0][0]))\n",
    "\n",
    "\n",
    "    #Opens my database (no security)\n",
    "    FBConn = firebase.FirebaseApplication('https://stock-price-predictor-9786f.firebaseio.com/', None)\n",
    "\n",
    "    #Uploading data without an ID specification\n",
    "    result = FBConn.put('/' + stock, 'RMSE', round(float(rmse), 2))\n",
    "    result = FBConn.put('/' + stock, 'Predicted Price', round(float(predicted_price[0][0]), 2))\n",
    "    result = FBConn.put('/' + stock, 'Date', today)\n",
    "    \n",
    "    print(stock + ' complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
